{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport random\n\ndirectory = '../input/celeba-dataset'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-04T20:05:54.334722Z","iopub.execute_input":"2022-01-04T20:05:54.335003Z","iopub.status.idle":"2022-01-04T20:05:59.805867Z","shell.execute_reply.started":"2022-01-04T20:05:54.334928Z","shell.execute_reply":"2022-01-04T20:05:59.804742Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"image_gen = ImageDataGenerator(rescale=1/255,\n                              validation_split=.05)\n\nheight = 256\nwidth = 256\nbatch_size = 64\n\ntraining_images = image_gen.flow_from_directory(directory,\n                                               class_mode=None,\n                                               target_size=(height,width),\n                                               batch_size=batch_size,\n                                               subset='training')\n\nvalidation_images = image_gen.flow_from_directory(directory,\n                                                 class_mode=None,\n                                                 target_size=(height,width),\n                                                 batch_size=batch_size,\n                                                 subset='validation')","metadata":{"execution":{"iopub.status.busy":"2022-01-04T20:05:59.810478Z","iopub.execute_input":"2022-01-04T20:05:59.812376Z","iopub.status.idle":"2022-01-04T20:11:00.900970Z","shell.execute_reply.started":"2022-01-04T20:05:59.812330Z","shell.execute_reply":"2022-01-04T20:11:00.900243Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def add_noise(image,height=height,width=width):\n    noise = tf.random.normal(shape=(height,width,3),\n                             mean=1,\n                             stddev=1.)/6\n    noisy_image = tf.add(image,noise)\n    noisy_image = tf.clip_by_value(noisy_image,\n                         clip_value_min=0,\n                         clip_value_max=1)\n    return noisy_image\n\ndef make_dataset(iterator,batch_size=batch_size,height=height,width=width,dtype=tf.float32):\n    \n    dataset = tf.data.Dataset.from_generator(lambda: (batch for batch in iterator),\n                                            output_signature=tf.TensorSpec(shape=(None,height,width,3),\n                                                                          dtype=dtype))\n    dataset = dataset.unbatch()\n    dataset = dataset.batch(batch_size,\n                           drop_remainder=True)\n    dataset = dataset.map(lambda batch: (add_noise(batch),batch))\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    \n    return dataset\n\ntrain_dataset = make_dataset(training_images)\nvalidation_dataset = make_dataset(validation_images)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T20:12:36.469501Z","iopub.execute_input":"2022-01-04T20:12:36.470094Z","iopub.status.idle":"2022-01-04T20:12:36.581731Z","shell.execute_reply.started":"2022-01-04T20:12:36.470056Z","shell.execute_reply":"2022-01-04T20:12:36.581077Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(' '*15+'Clean Images:'+' '*40+'Noisy Images:')\nfor i in range(10):\n    batch = next(iter(train_dataset))\n    num = random.randint(0,len(batch)-1)\n    clean_image = tf.cast(batch[1][num],tf.float64)\n    noisy_image = tf.cast(batch[0][num],tf.float64)\n    plt.figure(figsize=(12,6))\n    plt.subplot(1,2,1)\n    plt.imshow(clean_image)\n    plt.axis('off')\n    plt.subplot(1,2,2)\n    plt.imshow(noisy_image)\n    plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T20:13:41.784414Z","iopub.execute_input":"2022-01-04T20:13:41.784673Z","iopub.status.idle":"2022-01-04T20:13:51.474774Z","shell.execute_reply.started":"2022-01-04T20:13:41.784646Z","shell.execute_reply":"2022-01-04T20:13:51.474150Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"filters = 32\n\nencoder = keras.Sequential([\n    keras.layers.Conv2D(filters,(3,3),activation='elu',padding='same',input_shape=(height,width,3)),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.Conv2D(filters*2,(3,3),activation='elu'),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2D(filters*4,(3,3),activation='elu'),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.Conv2D(filters*8,(3,3),activation='elu'),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2D(filters*16,(3,3),activation='elu'),\n    keras.layers.MaxPooling2D(2),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2D(filters*32,(3,3),activation='elu'),\n    keras.layers.Conv2D(filters*32,(2,2),activation='elu')\n])\n\nencoder.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T20:13:59.922673Z","iopub.execute_input":"2022-01-04T20:13:59.922924Z","iopub.status.idle":"2022-01-04T20:14:00.065639Z","shell.execute_reply.started":"2022-01-04T20:13:59.922896Z","shell.execute_reply":"2022-01-04T20:14:00.064961Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"decoder = keras.Sequential([\n    keras.layers.Conv2DTranspose(filters*32,(3,3),activation='relu',input_shape=encoder.output.shape[1:]),\n    keras.layers.Conv2DTranspose(filters*32,(2,2),activation='relu'),\n    keras.layers.UpSampling2D(2),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2DTranspose(filters*16,(3,3),activation='relu'),\n    keras.layers.UpSampling2D(2),\n    keras.layers.Conv2DTranspose(filters*8,(3,3),activation='relu'),\n    keras.layers.UpSampling2D(2),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2DTranspose(filters*4,(3,3),activation='relu'),\n    keras.layers.UpSampling2D(2),\n    keras.layers.Conv2DTranspose(filters*2,(3,3),activation='relu'),\n    keras.layers.UpSampling2D(2),\n    keras.layers.Conv2DTranspose(filters,(3,3),activation='relu'),\n    keras.layers.Conv2DTranspose(3,(3,3),activation='sigmoid')\n])\n\ndecoder.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T20:18:14.832754Z","iopub.execute_input":"2022-01-04T20:18:14.833015Z","iopub.status.idle":"2022-01-04T20:18:14.983623Z","shell.execute_reply.started":"2022-01-04T20:18:14.832983Z","shell.execute_reply":"2022-01-04T20:18:14.982889Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"autoencoder = keras.Model(inputs=encoder.inputs,\n                         outputs=decoder(encoder.outputs))\n\noptimizer = keras.optimizers.Adam(learning_rate=1e-3)\n\ndef ssim(x,y):\n    return 1 - tf.image.ssim(x,y,max_val=1)\n\nautoencoder.compile(loss=ssim,\n                   optimizer=optimizer,\n                   metrics='mae')\n\nautoencoder.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T20:18:19.350693Z","iopub.execute_input":"2022-01-04T20:18:19.350947Z","iopub.status.idle":"2022-01-04T20:18:19.457691Z","shell.execute_reply.started":"2022-01-04T20:18:19.350919Z","shell.execute_reply":"2022-01-04T20:18:19.456673Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"lr_scheduler = keras.callbacks.LearningRateScheduler(schedule,\n                                                    verbose=1)\n\nepochs = 20\nsteps_per_epoch = len(training_images)/3\nvalidation_steps = len(validation_images)\n\nhistory = autoencoder.fit(train_dataset,\n                         validation_data=validation_dataset,\n                         epochs=epochs,\n                         steps_per_epoch=steps_per_epoch,\n                         validation_steps=validation_steps,\n                         callbacks=[reduce_lr])","metadata":{"execution":{"iopub.status.busy":"2022-01-04T20:18:23.275423Z","iopub.execute_input":"2022-01-04T20:18:23.275676Z","iopub.status.idle":"2022-01-04T23:20:46.835411Z","shell.execute_reply.started":"2022-01-04T20:18:23.275647Z","shell.execute_reply":"2022-01-04T23:20:46.834397Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"hist = history.history\nloss = hist['loss']\nmae = hist['mae']\nval_loss = hist['val_loss']\nval_mae = hist['val_mae']\nepoch = np.arange(1,epochs+1)\n\nsns.set_style('darkgrid')\nplt.figure(figsize=(12,7))\nplt.plot(epoch,loss)\nplt.plot(epoch,val_loss)\nplt.title('Training & Validation Loss (Mean Squared Error)',fontdict={'fontsize':20})\nplt.xlabel('Epoch',fontdict={'fontsize':16})\nplt.ylabel('Loss',fontdict={'fontsize':16})\nplt.legend(['Training Loss','Validation Loss'],prop={'size':18})\nplt.show()\n\nplt.figure(figsize=(12,7))\nplt.plot(epoch,mae)\nplt.plot(epoch,val_mae)\nplt.title('Training & Validation Mean Absolute Error',fontdict={'fontsize':20})\nplt.xlabel('Epoch',fontdict={'fontsize':16})\nplt.ylabel('Mean Absolute Error',fontdict={'fontsize':16})\nplt.legend(['Training MAE','Validation MAE'],prop={'size':18})\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T23:20:46.837324Z","iopub.execute_input":"2022-01-04T23:20:46.837780Z","iopub.status.idle":"2022-01-04T23:20:47.717721Z","shell.execute_reply.started":"2022-01-04T23:20:46.837738Z","shell.execute_reply":"2022-01-04T23:20:47.716961Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print('Denoising training images:')\nfor i in range(15):\n    batch_num = random.randint(0,len(training_images)-1)\n    batch = training_images[batch_num]\n    img_num = random.randint(0,len(batch)-1)\n    image = batch[img_num]\n    noisy_image = add_noise(image)\n    denoised_image = autoencoder(tf.expand_dims(noisy_image,axis=0)).numpy().squeeze()\n    plt.figure(figsize=(12,6))\n    plt.subplot(1,3,1)\n    plt.imshow(image)\n    plt.axis('off')\n    plt.subplot(1,3,2)\n    plt.imshow(noisy_image)\n    plt.axis('off')\n    plt.subplot(1,3,3)\n    plt.imshow(denoised_image)\n    plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T23:22:11.295840Z","iopub.execute_input":"2022-01-04T23:22:11.296091Z","iopub.status.idle":"2022-01-04T23:22:19.899761Z","shell.execute_reply.started":"2022-01-04T23:22:11.296062Z","shell.execute_reply":"2022-01-04T23:22:19.899047Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"print('Denoising validation images:')\nfor i in range(15):\n    batch_num = random.randint(0,len(validation_images)-1)\n    batch = validation_images[batch_num]\n    img_num = random.randint(0,len(batch)-1)\n    image = batch[img_num]\n    noisy_image = add_noise(image)\n    denoised_image = autoencoder(tf.expand_dims(noisy_image,axis=0)).numpy().squeeze()\n    plt.figure(figsize=(12,6))\n    plt.subplot(1,3,1)\n    plt.imshow(image)\n    plt.axis('off')\n    plt.subplot(1,3,2)\n    plt.imshow(noisy_image)\n    plt.axis('off')\n    plt.subplot(1,3,3)\n    plt.imshow(denoised_image)\n    plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T23:22:32.942472Z","iopub.execute_input":"2022-01-04T23:22:32.942723Z","iopub.status.idle":"2022-01-04T23:22:41.251685Z","shell.execute_reply.started":"2022-01-04T23:22:32.942695Z","shell.execute_reply":"2022-01-04T23:22:41.251048Z"},"trusted":true},"execution_count":20,"outputs":[]}]}